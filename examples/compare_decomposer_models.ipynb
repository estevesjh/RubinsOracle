{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Decomposer Forecasting Comparison\n",
    "\n",
    "This notebook compares forecasting performance across different approaches:\n",
    "\n",
    "1. **Vanilla Prophet** - Baseline Prophet with custom seasonalities\n",
    "2. **Vanilla NeuralProphet** - NeuralProphet without decomposition\n",
    "3. **NeuralProphet + HighLowFreqDecomposer** - 2-band decomposition (12h, 24h, low_freq)\n",
    "4. **NeuralProphet + SignalDecomposer (5-band)** - Multi-scale decomposition (sub-daily, daily, weekly, bi-weekly, monthly)\n",
    "5. **EnsembleForecaster** - Combines specialized high-freq and low-freq NeuralProphet models\n",
    "\n",
    "The key innovation is the new `SignalDecomposer` / `HighLowFreqDecomposer` that:\n",
    "- Uses Prophet to extend the signal forward before decomposition\n",
    "- Pushes edge effects into the discarded future portion\n",
    "- Provides sklearn-style fit/transform API\n",
    "\n",
    "The `EnsembleForecaster` builds on this by:\n",
    "- Using separate configs for high-freq and low-freq models\n",
    "- Each model optimized for its frequency band\n",
    "- Simple summation combines the forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from rubin_oracle import (\n",
    "    ProphetConfig,\n",
    "    ProphetForecaster,\n",
    "    NeuralProphetConfig,\n",
    "    NeuralProphetForecaster,\n",
    "    HighLowFreqDecomposer,\n",
    "    SignalDecomposer,\n",
    ")\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"temp2024.csv\"\n",
    "CONFIGS_PATH = PROJECT_ROOT / \"configs\"\n",
    "\n",
    "# Constants - Using HOURLY frequency\n",
    "STEPS_PER_HOUR = 1\n",
    "STEPS_PER_DAY = 24\n",
    "\n",
    "# Styling\n",
    "sns.set_context(\"notebook\", font_scale=0.9)\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 6)\n",
    "\n",
    "COLORS = {\n",
    "    \"actual\": \"#2c3e50\",\n",
    "    \"prophet\": \"#95a5a6\",\n",
    "    \"np_vanilla\": \"#3498db\",\n",
    "    \"np_decomp\": \"#e74c3c\",\n",
    "    \"np_5band\": \"#9b59b6\",\n",
    "}\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Using HOURLY frequency: {STEPS_PER_DAY} samples/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temperature data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"ds\"] = pd.to_datetime(df[\"ds\"], utc=True).dt.tz_convert(\"America/Santiago\")\n",
    "df = df[[\"ds\", \"y\"]].copy()\n",
    "\n",
    "# Remove timezone for Prophet compatibility\n",
    "df[\"ds\"] = df[\"ds\"].dt.tz_localize(None)\n",
    "\n",
    "# Drop duplicates (DST transitions can create duplicates)\n",
    "df = df.drop_duplicates(subset=\"ds\", keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Raw dataset: {len(df):,} samples ({len(df) / 96:.1f} days at 15-min)\")\n",
    "\n",
    "# Resample to hourly frequency\n",
    "df = df.set_index(\"ds\").resample(\"1h\").mean().reset_index()\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Resampled to hourly: {len(df):,} samples ({len(df) / STEPS_PER_DAY:.1f} days)\")\n",
    "print(f\"Date range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "print(\"\\nSample data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 300 days for training, forecast 24h ahead\n",
    "TRAIN_DAYS = 120\n",
    "FORECAST_HORIZON = 24  # 24 samples = 24 hours at hourly freq\n",
    "\n",
    "train_samples = TRAIN_DAYS * STEPS_PER_DAY + 3\n",
    "df_train = df.iloc[:train_samples].copy()\n",
    "df_test = df.iloc[train_samples:train_samples + FORECAST_HORIZON].copy()\n",
    "\n",
    "print(f\"Training: {len(df_train):,} samples ({len(df_train) / STEPS_PER_DAY:.0f} days)\")\n",
    "print(f\"Test: {len(df_test)} samples ({len(df_test)} hours)\")\n",
    "print(f\"\\nForecast start: {df_test['ds'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Vanilla Prophet (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting Vanilla Prophet...\")\n",
    "\n",
    "# Load config\n",
    "prophet_config = ProphetConfig.from_yaml(CONFIGS_PATH / \"prophet_default.yaml\")\n",
    "print(f\"Config: {prophet_config.name}\")\n",
    "\n",
    "# Fit\n",
    "prophet_model = ProphetForecaster(prophet_config)\n",
    "prophet_model.fit(df_train)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nProphet Metrics:\")\n",
    "for key, val in prophet_model.metrics_.items():\n",
    "    print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")\n",
    "\n",
    "# Forecast\n",
    "prophet_fc = prophet_model.forecast()\n",
    "yhat_prophet = prophet_fc[\"yhat\"].values\n",
    "\n",
    "# Bias correction\n",
    "bias = df_train[\"y\"].iloc[-1] - yhat_prophet[0]\n",
    "yhat_prophet_corrected = yhat_prophet + bias\n",
    "\n",
    "y_true = df_test[\"y\"].values\n",
    "rmse_prophet = np.sqrt(((y_true - yhat_prophet_corrected) ** 2).mean())\n",
    "print(f\"\\nProphet Forecast RMSE (with bias correction): {rmse_prophet:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prophet\n",
    "prophet_model.plot(df_test=df_test, window_days=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Vanilla NeuralProphet (No Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting Vanilla NeuralProphet...\")\n",
    "\n",
    "# Load config (already has freq: 1h)\n",
    "np_config = NeuralProphetConfig.from_yaml(CONFIGS_PATH / \"neuralprophet_default.yaml\")\n",
    "\n",
    "# Reduce epochs for faster testing\n",
    "np_config_dict = np_config.model_dump()\n",
    "np_config_dict[\"epochs\"] = 30\n",
    "np_config_dict[\"lag_days\"] = 1\n",
    "np_config = NeuralProphetConfig.model_validate(np_config_dict)\n",
    "\n",
    "print(f\"Config: {np_config.name}\")\n",
    "print(f\"Freq: {np_config.freq}, Lag days: {np_config.lag_days}, Epochs: {np_config.epochs}\")\n",
    "\n",
    "# Fit\n",
    "np_vanilla = NeuralProphetForecaster(np_config)\n",
    "np_vanilla.fit(df_train, verbose=True)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nVanilla NeuralProphet Metrics:\")\n",
    "for key, val in np_vanilla.metrics_.items():\n",
    "    print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")\n",
    "\n",
    "# Forecast\n",
    "np_vanilla_fc = np_vanilla.forecast(df_test, np_vanilla.latest_timestamp)\n",
    "yhat_np_vanilla = np_vanilla_fc[\"yhat\"].values\n",
    "\n",
    "rmse_np_vanilla = np.sqrt(((y_true - yhat_np_vanilla) ** 2).mean())\n",
    "print(f\"\\nVanilla NeuralProphet Forecast RMSE: {rmse_np_vanilla:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NeuralProphet vanilla\n",
    "np_vanilla.plot(df_test=df_test, window_days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73511f36-56be-4a73-9bf2-cb7eda9ea85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. NeuralProphet + HighLowFreqDecomposer (External Decomposition)\n",
    "\n",
    "This approach uses the new `HighLowFreqDecomposer` which:\n",
    "- Extends signal forward using Prophet before decomposition\n",
    "- Extracts `y_high_12h`, `y_high_24h`, and `y_low_freq` components\n",
    "- Pushes edge effects into the future (discarded) portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up HighLowFreqDecomposer...\")\n",
    "\n",
    "# Create decomposer\n",
    "decomposer = HighLowFreqDecomposer(\n",
    "    freq=STEPS_PER_DAY,\n",
    "    extension_days=2.0,\n",
    "    history_buffer_days=14.0,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Fit and transform training data\n",
    "print(\"\\nDecomposing training data...\")\n",
    "decomposer.fit(df_train.tail(14 * 24))\n",
    "df_train_decomposed = decomposer.transform(df_train)\n",
    "df_train_decomposed_all = decomposer.fit_transform(df).iloc[:train_samples].copy()\n",
    "\n",
    "print(f\"\\nDecomposed columns: {list(df_train_decomposed.columns)}\")\n",
    "print(f\"Feature names: {decomposer.get_feature_names()}\")\n",
    "print(f\"Training end: {decomposer.training_end_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9cbde9-a037-41db-9006-aff79ca22acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decomposition\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Last 7 days of training\n",
    "n_plot = 7 * STEPS_PER_DAY\n",
    "df_plot = df_train_decomposed.tail(n_plot)\n",
    "\n",
    "axes[0].plot(df_plot[\"ds\"], df_plot[\"y\"], \"k\", lw=0.8)\n",
    "axes[0].set_ylabel(\"Original (°C)\")\n",
    "axes[0].set_title(\"HighLowFreqDecomposer Signal Decomposition\", fontsize=14)\n",
    "\n",
    "# axes[1].plot(df_plot[\"ds\"], df_plot[\"y_high_12h\"], color=\"#e74c3c\", lw=1.2)\n",
    "# axes[1].set_ylabel(\"y_high_12h (°C)\")\n",
    "# axes[1].axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "axes[1].plot(df_plot[\"ds\"], df_plot[\"y_high_24h\"], color=\"#3498db\", lw=1.2)\n",
    "axes[1].set_ylabel(\"y_high_24h (°C)\")\n",
    "axes[1].axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "axes[2].plot(df_plot[\"ds\"], df_plot[\"y_low_freq\"], color=\"#27ae60\", lw=1.2)\n",
    "axes[2].set_ylabel(\"y_low_freq (°C)\")\n",
    "axes[2].set_xlabel(\"Date\")\n",
    "\n",
    "\n",
    "# Last 7 days of training\n",
    "n_plot = 7 * STEPS_PER_DAY\n",
    "df_plot = df_train_decomposed_all.tail(n_plot)\n",
    "\n",
    "axes[0].plot(df_plot[\"ds\"], df_plot[\"y\"], \"k\", lw=0.8)\n",
    "axes[0].set_ylabel(\"Original (°C)\")\n",
    "axes[0].set_title(\"HighLowFreqDecomposer Signal Decomposition\", fontsize=14)\n",
    "\n",
    "# axes[1].plot(df_plot[\"ds\"], df_plot[\"y_high_12h\"], color=\"grey\", lw=0.8)\n",
    "# axes[1].set_ylabel(\"y_high_12h (°C)\")\n",
    "# axes[1].axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "axes[1].plot(df_plot[\"ds\"], df_plot[\"y_high_24h\"], color=\"grey\", lw=0.8)\n",
    "axes[1].set_ylabel(\"y_high_24h (°C)\")\n",
    "axes[1].axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "axes[2].plot(df_plot[\"ds\"], df_plot[\"y_low_freq\"], color=\"grey\", lw=0.8)\n",
    "axes[2].set_ylabel(\"y_low_freq (°C)\")\n",
    "axes[2].set_xlabel(\"Date\")\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Variance breakdown\n",
    "print(\"\\nVariance breakdown:\")\n",
    "total_var = df_train_decomposed[\"y\"].var()\n",
    "for col in decomposer.get_feature_names():\n",
    "    var = df_train_decomposed[col].var()\n",
    "    print(f\"  {col}: {var:.4f} ({var/total_var*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting NeuralProphet with external decomposition...\")\n",
    "\n",
    "# Load config (already has 1h frequency, no internal decomposition)\n",
    "np_decomp_config = NeuralProphetConfig.from_yaml(CONFIGS_PATH / \"neuralprophet_external_decomp.yaml\")\n",
    "\n",
    "print(f\"Config: {np_decomp_config.name}\")\n",
    "print(f\"Freq: {np_decomp_config.freq}, Lag days: {np_decomp_config.lag_days}, Epochs: {np_decomp_config.epochs}\")\n",
    "print(f\"Internal decomposer: {np_decomp_config.decomposer.method}\")\n",
    "\n",
    "# Fit on decomposed data with explicit regressors\n",
    "np_decomp = NeuralProphetForecaster(np_decomp_config)\n",
    "np_decomp.fit(\n",
    "    df_train_decomposed,\n",
    "    verbose=True,\n",
    "    regressors=decomposer.get_feature_names(),  # Explicitly pass decomposed columns\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nNeuralProphet + HighLowFreq Decomposer Metrics:\")\n",
    "for key, val in np_decomp.metrics_.items():\n",
    "    print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data using the decomposer\n",
    "print(\"Decomposing test data (with Prophet extension)...\")\n",
    "df_test_decomposed = decomposer.transform(df_test)\n",
    "\n",
    "print(f\"Test decomposed shape: {df_test_decomposed.shape}\")\n",
    "print(f\"NaN values: {df_test_decomposed[decomposer.get_feature_names()].isna().sum().sum()}\")\n",
    "\n",
    "# Forecast\n",
    "np_decomp_fc = np_decomp.forecast(df_test_decomposed, np_decomp.latest_timestamp)\n",
    "yhat_np_decomp = np_decomp_fc[\"yhat\"].values\n",
    "\n",
    "# Handle potential length mismatch\n",
    "n_pred = min(len(y_true), len(yhat_np_decomp))\n",
    "rmse_np_decomp = np.sqrt(((y_true[:n_pred] - yhat_np_decomp[:n_pred]) ** 2).mean())\n",
    "print(f\"\\nNeuralProphet + HighLowFreqDecomposer Forecast RMSE: {rmse_np_decomp:.4f}\")\n",
    "print(f\"Predictions: {len(yhat_np_decomp)} / {len(y_true)} expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NeuralProphet with decomposer\n",
    "np_decomp.plot(df_test=df_test_decomposed, window_days=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mb2o76x8fu",
   "metadata": {},
   "source": [
    "## 6. NeuralProphet + SignalDecomposer (5-band)\n",
    "\n",
    "Multi-scale decomposition with 5 frequency bands:\n",
    "- **Band 0**: Sub-daily (0.1-0.8 days = 2.4-19.2 hours)\n",
    "- **Band 1**: Daily (0.8-1.5 days = 19.2-36 hours)\n",
    "- **Band 2**: Weekly (1.5-4 days)\n",
    "- **Band 3**: Bi-weekly (4-25 days)\n",
    "- **Band 4**: Monthly (25-60 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su3akpzquhb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up SignalDecomposer (5-band)...\")\n",
    "\n",
    "# 5-band period pairs\n",
    "PERIOD_PAIRS_5BAND = [\n",
    "    (0.10, 0.80),   # Band 0: Sub-daily (< 17h)\n",
    "    (0.80, 1.50),   # Band 1: Daily (17h - 36h)\n",
    "    (1.5, 7.00),   # Band 2: Weekly (1.5-4d)\n",
    "    (7.00, 25.00),  # Band 3: Bi-weekly (4-25d)\n",
    "    (25.00, 60.00), # Band 4: Monthly (25-60d)\n",
    "]\n",
    "\n",
    "decomposer_5band = SignalDecomposer(\n",
    "    freq=STEPS_PER_DAY,\n",
    "    period_pairs=PERIOD_PAIRS_5BAND,\n",
    "    extension_days=2.0,\n",
    "    history_buffer_days=14.0,\n",
    "    filter_type = \"butterworth\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Fit and transform training data\n",
    "print(\"\\nDecomposing training data (5-band)...\")\n",
    "decomposer_5band.fit(df_train.tail(14 * STEPS_PER_DAY))\n",
    "df_train_5band = decomposer_5band.transform(df_train)\n",
    "df_train_5band_all = decomposer_5band.transform(df).iloc[:train_samples].copy()\n",
    "\n",
    "print(f\"\\nDecomposed columns: {list(df_train_5band.columns)}\")\n",
    "print(f\"Feature names: {decomposer_5band.get_feature_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s0bvn96yqfk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 5-band decomposition\n",
    "fig, axes = plt.subplots(6, 1, figsize=(14, 14), sharex=True)\n",
    "\n",
    "n_plot = 7 * STEPS_PER_DAY\n",
    "df_plot = df_train_5band.tail(n_plot)\n",
    "band_names = [\"Sub-daily\", \"Daily\", \"Weekly\", \"Bi-weekly\", \"Monthly\"]\n",
    "band_colors = [\"#e74c3c\", \"#3498db\", \"#27ae60\", \"#f39c12\", \"#9b59b6\"]\n",
    "\n",
    "axes[0].plot(df_plot[\"ds\"], df_plot[\"y\"], \"k\", lw=0.8)\n",
    "axes[0].set_ylabel(\"Original (°C)\")\n",
    "axes[0].set_title(\"SignalDecomposer 5-Band Decomposition\", fontsize=14)\n",
    "\n",
    "for i, (name, color) in enumerate(zip(band_names, band_colors)):\n",
    "    col = f\"y_band_{i}\"\n",
    "    axes[i+1].plot(df_plot[\"ds\"], df_plot[col], color=color, lw=1.2)\n",
    "    axes[i+1].set_ylabel(f\"{name} (°C)\")\n",
    "    axes[i+1].axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "df_plot = df_train_5band_all.tail(n_plot)\n",
    "for i, (name, color) in enumerate(zip(band_names, band_colors)):\n",
    "    col = f\"y_band_{i}\"\n",
    "    axes[i+1].plot(df_plot[\"ds\"], df_plot[col], color=\"grey\", lw=0.8, ls='--')\n",
    "    axes[i+1].set_ylabel(f\"{name} (°C)\")\n",
    "    axes[i+1].axhline(0, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "    lims = [df_plot[col].mean()-3*df_plot[col].std(), df_plot[col].mean()+3*df_plot[col].std()]\n",
    "    axes[i+1].set_ylim(*lims)\n",
    "\n",
    "axes[-1].set_xlabel(\"Date\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Variance breakdown\n",
    "print(\"\\nVariance breakdown (5-band):\")\n",
    "total_var = df_train_5band[\"y\"].var()\n",
    "for i, name in enumerate(band_names):\n",
    "    col = f\"y_band_{i}\"\n",
    "    var = df_train_5band[col].var()\n",
    "    print(f\"  {name} ({col}): {var:.4f} ({var/total_var*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yg1j83lxc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting NeuralProphet with 5-band decomposition...\")\n",
    "\n",
    "# Use same config as HighLowFreq (already has 1h frequency)\n",
    "np_5band_config = NeuralProphetConfig.from_yaml(CONFIGS_PATH / \"neuralprophet_external_decomp.yaml\")\n",
    "\n",
    "print(f\"Config: {np_5band_config.name}\")\n",
    "print(f\"Freq: {np_5band_config.freq}, Lag days: {np_5band_config.lag_days}, Epochs: {np_5band_config.epochs}\")\n",
    "\n",
    "# Fit on 5-band decomposed data with explicit regressors\n",
    "np_5band = NeuralProphetForecaster(np_5band_config)\n",
    "np_5band.fit(\n",
    "    df_train_5band,\n",
    "    verbose=True,\n",
    "    regressors=decomposer_5band.get_feature_names(),  # Explicitly pass 5 band columns\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nNeuralProphet + 5-band Decomposer Metrics:\")\n",
    "for key, val in np_5band.metrics_.items():\n",
    "    print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0nzk799o0h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data using 5-band decomposer\n",
    "print(\"Decomposing test data (5-band with Prophet extension)...\")\n",
    "# np_5band._fit_df = df_train_5band\n",
    "# np_5band.latest_timestamp = df_train['ds'].max().tz_localize(\"America/Santiago\")\n",
    "\n",
    "df_test_5band = decomposer_5band.transform(df_test)\n",
    "\n",
    "print(f\"Test decomposed shape: {df_test_5band.shape}\")\n",
    "print(f\"NaN values: {df_test_5band[decomposer_5band.get_feature_names()].isna().sum().sum()}\")\n",
    "\n",
    "# Forecast\n",
    "np_5band_fc = np_5band.forecast(df_test_5band, np_5band.latest_timestamp)\n",
    "yhat_np_5band = np_5band_fc[\"yhat\"].values\n",
    "\n",
    "# Handle potential length mismatch\n",
    "n_pred = min(len(y_true), len(yhat_np_5band))\n",
    "rmse_np_5band = np.sqrt(((y_true[:n_pred] - yhat_np_5band[:n_pred]) ** 2).mean())\n",
    "print(f\"\\nNeuralProphet + 5-band Decomposer Forecast RMSE: {rmse_np_5band:.4f}\")\n",
    "print(f\"Predictions: {len(yhat_np_5band)} / {len(y_true)} expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f56f18-fd19-4512-b50a-2310bb70a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_5band.plot(df_test=df_test_5band, window_days=5, lead_time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc4ad3-c109-44eb-8c60-6ee52cd14530",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = y_true[0]-yhat_np_5band[0]\n",
    "plt.plot(yhat_np_5band+bias)\n",
    "plt.plot(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b16ff0-b0db-40ec-acdc-4545bd4c040a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7050eb3-9f40-4424-89ea-9ee6ad3b3434",
   "metadata": {},
   "source": [
    "## 7. EnsembleForecaster (High + Low Frequency Models)\n",
    "\n",
    "The new `EnsembleForecaster` combines two separate NeuralProphet models:\n",
    "- **High-frequency model**: Optimized for fast-changing components (12h, 24h bands)\n",
    "- **Low-frequency model**: Optimized for slow-changing components (weekly+ bands)\n",
    "\n",
    "Key benefits:\n",
    "- Each model has hyperparameters tuned for its frequency band\n",
    "- Decomposition happens externally (separation of concerns)\n",
    "- Simple summation combines the forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cyvpyo4b66n",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubin_oracle import EnsembleForecaster, NeuralProphetConfig\n",
    "\n",
    "print(\"Setting up EnsembleForecaster...\")\n",
    "\n",
    "# Load configs for high-freq and low-freq models\n",
    "high_freq_config = NeuralProphetConfig.from_yaml(CONFIGS_PATH / \"neuralprophet_high_freq.yaml\")\n",
    "low_freq_config = NeuralProphetConfig.from_yaml(CONFIGS_PATH / \"neuralprophet_low_freq.yaml\")\n",
    "\n",
    "print(f\"High-freq config: lag_days={high_freq_config.lag_days}, epochs={high_freq_config.epochs}, ar_layers={high_freq_config.ar_layers}\")\n",
    "print(f\"Low-freq config: lag_days={low_freq_config.lag_days}, epochs={low_freq_config.epochs}, ar_layers={low_freq_config.ar_layers}\")\n",
    "\n",
    "# Create ensemble with column mappings from 5-band decomposition\n",
    "# High-freq: bands 0, 1 (sub-daily + daily)\n",
    "# Low-freq: bands 2, 3, 4 (weekly, bi-weekly, monthly)\n",
    "ensemble = EnsembleForecaster(\n",
    "    high_freq_config=high_freq_config,\n",
    "    low_freq_config=low_freq_config,\n",
    "    high_freq_cols=[\"y_band_0\", \"y_band_1\", \"y_band_2\"],\n",
    "    low_freq_cols=[\"y_band_3\", \"y_band_4\"],\n",
    "    bias_correction=True,\n",
    "    bias_window_hours=6.0,\n",
    ")\n",
    "\n",
    "print(f\"\\nHigh-freq columns: {ensemble._high_freq_cols}\")\n",
    "print(f\"Low-freq columns: {ensemble._low_freq_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8mwntr0l",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting EnsembleForecaster on pre-decomposed data...\")\n",
    "\n",
    "# Use the 5-band decomposed training data (already created earlier)\n",
    "ensemble.fit(df_train_5band, verbose=True)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nEnsembleForecaster Metrics:\")\n",
    "for key, val in ensemble.metrics_.items():\n",
    "    print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19297dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_5band = decomposer_5band.transform(df_test, include_history=True)\n",
    "df_test_5band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9xemudxm2bl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ensemble forecast on pre-decomposed test data\n",
    "print(\"Generating ensemble forecast...\")\n",
    "ensemble_fc = ensemble.fitted().drop_duplicates(\"ds\").groupby(\"ds\").first().reset_index().tail(25)\n",
    "yhat_ensemble = ensemble_fc[\"yhat\"].values\n",
    "\n",
    "# Compute RMSE\n",
    "n_pred = min(len(y_true), len(yhat_ensemble))\n",
    "rmse_ensemble = np.sqrt(((y_true[:n_pred] - yhat_ensemble[:n_pred]) ** 2).mean())\n",
    "print(f\"\\nEnsembleForecaster Forecast RMSE: {rmse_ensemble:.4f}\")\n",
    "print(f\"Predictions: {len(yhat_ensemble)} / {len(y_true)} expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fm6zoa663cv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ensemble forecast with component breakdown\n",
    "fig, axs = ensemble.plot(df_test=df_test_5band, window_days=4, show_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d678fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a75cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.plot_components(window_days=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Forecast Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all forecasts\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "hours = np.arange(FORECAST_HORIZON)\n",
    "\n",
    "# Add ensemble color\n",
    "COLORS[\"ensemble\"] = \"#2ecc71\"\n",
    "\n",
    "# Actual\n",
    "ax.plot(hours, y_true, \"-\", color=COLORS[\"actual\"], lw=2.5, label=\"Actual\")\n",
    "\n",
    "# Prophet\n",
    "ax.plot(\n",
    "    hours, yhat_prophet_corrected, \"--\",\n",
    "    color=COLORS[\"prophet\"], lw=1.5,\n",
    "    label=f\"Prophet (RMSE={rmse_prophet:.3f})\"\n",
    ")\n",
    "\n",
    "# Vanilla NeuralProphet\n",
    "ax.plot(\n",
    "    hours, yhat_np_vanilla, \"-\",\n",
    "    color=COLORS[\"np_vanilla\"], lw=1.5,\n",
    "    label=f\"NeuralProphet Vanilla (RMSE={rmse_np_vanilla:.3f})\"\n",
    ")\n",
    "\n",
    "# NeuralProphet + HighLow Decomposer\n",
    "ax.plot(\n",
    "    hours, yhat_np_decomp, \"-\",\n",
    "    color=COLORS[\"np_decomp\"], lw=1.5,\n",
    "    label=f\"NeuralProphet + HighLow (RMSE={rmse_np_decomp:.3f})\"\n",
    ")\n",
    "\n",
    "# NeuralProphet + 5-band Decomposer\n",
    "ax.plot(\n",
    "    hours, yhat_np_5band, \"-\",\n",
    "    color=COLORS[\"np_5band\"], lw=1.5,\n",
    "    label=f\"NeuralProphet + 5-band (RMSE={rmse_np_5band:.3f})\"\n",
    ")\n",
    "\n",
    "# EnsembleForecaster\n",
    "ax.plot(\n",
    "    hours, yhat_ensemble[:24], \"-\",\n",
    "    color=COLORS[\"ensemble\"], lw=2,\n",
    "    label=f\"Ensemble (RMSE={rmse_ensemble:.3f})\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Forecast Horizon (hours)\", fontsize=12)\n",
    "ax.set_ylabel(\"Temperature (°C)\", fontsize=12)\n",
    "ax.set_title(\"24h Forecast Comparison: Decomposer vs Vanilla Models\", fontsize=14)\n",
    "ax.legend(fontsize=10, loc=\"best\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. RMSE by Lead Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rolling RMSE\n",
    "def rolling_rmse(y_true, yhat, window=4):\n",
    "    rmse = []\n",
    "    for i in range(len(y_true)):\n",
    "        start = max(0, i - window + 1)\n",
    "        rmse.append(np.sqrt(np.mean((y_true[start:i+1] - yhat[start:i+1]) ** 2)))\n",
    "    return np.array(rmse)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "hours = np.arange(FORECAST_HORIZON)\n",
    "\n",
    "ax.plot(hours, rolling_rmse(y_true, yhat_prophet_corrected), \"-\",\n",
    "        color=COLORS[\"prophet\"], lw=2, label=\"Prophet\")\n",
    "ax.plot(hours, rolling_rmse(y_true, yhat_np_vanilla), \"-\",\n",
    "        color=COLORS[\"np_vanilla\"], lw=2, label=\"NeuralProphet Vanilla\")\n",
    "ax.plot(hours, rolling_rmse(y_true, yhat_np_decomp), \"-\",\n",
    "        color=COLORS[\"np_decomp\"], lw=2, label=\"NeuralProphet + HighLow\")\n",
    "ax.plot(hours, rolling_rmse(y_true, yhat_np_5band), \"-\",\n",
    "        color=COLORS[\"np_5band\"], lw=2, label=\"NeuralProphet + 5-band\")\n",
    "ax.plot(hours, rolling_rmse(y_true, yhat_ensemble), \"-\",\n",
    "        color=COLORS[\"ensemble\"], lw=2, label=\"Ensemble\")\n",
    "\n",
    "ax.axhline(y=1.0, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"1°C threshold\")\n",
    "ax.set_xlabel(\"Forecast Horizon (hours)\", fontsize=12)\n",
    "ax.set_ylabel(\"Rolling RMSE (°C)\", fontsize=12)\n",
    "ax.set_title(\"Rolling RMSE by Lead Time\", fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 24)\n",
    "ax.set_ylim(0, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY: 24h Forecast RMSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"Prophet (baseline)\",\n",
    "        \"NeuralProphet Vanilla\",\n",
    "        \"NeuralProphet + HighLowFreq\",\n",
    "        \"NeuralProphet + 5-band\",\n",
    "        \"EnsembleForecaster\",\n",
    "    ],\n",
    "    \"RMSE\": [rmse_prophet, rmse_np_vanilla, rmse_np_decomp, rmse_np_5band, rmse_ensemble],\n",
    "    \"In-sample R²\": [\n",
    "        prophet_model.metrics_[\"r2\"],\n",
    "        np_vanilla.metrics_[\"r2\"],\n",
    "        np_decomp.metrics_[\"r2\"],\n",
    "        np_5band.metrics_[\"r2\"],\n",
    "        \"N/A\",  # Ensemble has component metrics\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results[\"Improvement vs Prophet\"] = df_results[\"RMSE\"].apply(\n",
    "    lambda x: f\"{(rmse_prophet - x) / rmse_prophet * 100:+.1f}%\"\n",
    ")\n",
    "\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "best_idx = df_results[\"RMSE\"].idxmin()\n",
    "best_model = df_results.loc[best_idx, \"Model\"]\n",
    "best_rmse = df_results.loc[best_idx, \"RMSE\"]\n",
    "print(f\"BEST MODEL: {best_model} (RMSE: {best_rmse:.4f})\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 11. Save/Load Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    save_path = Path(tmpdir) / \"np_decomp_model\"\n",
    "\n",
    "    # Save forecaster with decomposer\n",
    "    print(\"Saving model with decomposer...\")\n",
    "    np_decomp.save(save_path, decomposer=decomposer)\n",
    "    print(f\"Saved files: {[f.name for f in save_path.iterdir()]}\")\n",
    "\n",
    "    # Load\n",
    "    print(\"\\nLoading model...\")\n",
    "    loaded_model = NeuralProphetForecaster.load(save_path)\n",
    "    loaded_decomposer = NeuralProphetForecaster.load_decomposer(save_path)\n",
    "\n",
    "    # Refit history (needed after loading without history)\n",
    "    print(\"Refitting decomposer history...\")\n",
    "    loaded_decomposer.refit_history(df_train)\n",
    "\n",
    "    # Get latest timestamp from training data\n",
    "    issue_time = df_train[\"ds\"].max()\n",
    "\n",
    "    # Verify prediction\n",
    "    df_test_decomp_loaded = loaded_decomposer.transform(df_test)\n",
    "    fc_loaded = loaded_model.forecast(df_test_decomp_loaded, issue_time=issue_time)\n",
    "\n",
    "    print(f\"\\nLoaded model prediction shape: {fc_loaded.shape}\")\n",
    "    print(f\"Loaded model RMSE: {np.sqrt(((y_true - fc_loaded['yhat'].values) ** 2).mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d66a57-d346-46b4-b900-852f0542a0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 12. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **HighLowFreqDecomposer** provides clean separation of signal into sub-daily, daily, and low-frequency components\n",
    "2. **Prophet extension** before decomposition eliminates edge effects in the decomposed signal\n",
    "3. **External decomposition** allows more flexibility than internal NeuralProphet decomposition\n",
    "4. **EnsembleForecaster** combines specialized models for different frequency bands\n",
    "\n",
    "### New API Features\n",
    "\n",
    "- `SignalDecomposer.fit_transform(df)` - Fit and decompose training data\n",
    "- `SignalDecomposer.transform(df)` - Decompose test data with automatic extension\n",
    "- `SignalDecomposer.get_feature_names()` - Get decomposed column names\n",
    "- `EnsembleForecaster(high_freq_config, low_freq_config, ...)` - Combine models for different frequency bands\n",
    "- `NeuralProphetForecaster.save(path, decomposer=...)` - Save with decomposer\n",
    "- `NeuralProphetForecaster.load_decomposer(path)` - Load decomposer separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e95e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b97a7df",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
